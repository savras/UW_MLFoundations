{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sales = graphlab.SFrame('kc_house_data.gl/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # note this allows us to refer to numpy as np instead "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(data_sframe, features, output):\n",
    "    data_sframe['constant'] = 1 # this is how you add a constant column to an SFrame\n",
    "    # add the column 'constant' to the front of the features list so that we can extract it along with the others:\n",
    "    features = ['constant'] + features # this is how you combine two lists\n",
    "    # select the columns of data_SFrame given by the features list into the SFrame features_sframe (now including constant):\n",
    "    features_sframe = data_sframe[features] # A numpy matrix whose columns are the desired features plus a constant column (this is how we create an 'intercept')\n",
    "    # the following line will convert the features_SFrame into a numpy matrix:\n",
    "    feature_matrix = features_sframe.to_numpy()\n",
    "    # assign the column of data_sframe associated with the output to the SArray output_sarray\n",
    "    output_sarray = data_sframe[output] # A numpy array containing the values of the output\n",
    "    # the following will convert the SArray into a numpy array by first converting it to a list\n",
    "    output_array = output_sarray.to_numpy()\n",
    "    return(feature_matrix, output_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing let's use the 'sqft_living' feature and a constant as our features and price as our output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.00000000e+00   1.18000000e+03]\n",
      "221900.0\n"
     ]
    }
   ],
   "source": [
    "(example_features, example_output) = get_numpy_data(sales, ['sqft_living'], 'price') # the [] around 'sqft_living' makes it a list\n",
    "print example_features[0,:] # this accesses the first row of the data the ':' indicates 'all columns'\n",
    "print example_output[0] # and the corresponding output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.00000000e+00   1.18000000e+03]\n",
      " [  1.00000000e+00   2.57000000e+03]\n",
      " [  1.00000000e+00   7.70000000e+02]\n",
      " ..., \n",
      " [  1.00000000e+00   1.02000000e+03]\n",
      " [  1.00000000e+00   1.60000000e+03]\n",
      " [  1.00000000e+00   1.02000000e+03]]\n"
     ]
    }
   ],
   "source": [
    "print(example_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting output given regression weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_output(feature_matrix, weights):\n",
    "    # assume feature_matrix is a numpy matrix containing the features as columns and weights is a corresponding numpy array\n",
    "    # create the predictions vector by using np.dot()\n",
    "    predictions = np.dot(feature_matrix, weights)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1181.0\n",
      "2571.0\n"
     ]
    }
   ],
   "source": [
    "my_weights = np.array([1., 1.]) # the example weights\n",
    "my_features = example_features[0,] # we'll use the first data point\n",
    "test_predictions = predict_output(example_features, my_weights)\n",
    "# We are just multiplying the features by 1\n",
    "print test_predictions[0] # should be 1181.0\n",
    "print test_predictions[1] # should be 2571.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the Derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):\n",
    "    # Assume that errors and feature are both numpy arrays of the same length (number of data points)\n",
    "    # compute twice the dot product of these vectors as 'derivative' and return the value\n",
    "    derivative = 2*np.dot(errors,feature)\n",
    "    return(derivative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions: [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "Example outputs: [ 221900.  538000.  180000. ...,  402101.  400000.  325000.]\n",
      "[-221900. -538000. -180000. ..., -402101. -400000. -325000.]\n",
      "Example features: [[  1.00000000e+00   1.18000000e+03]\n",
      " [  1.00000000e+00   2.57000000e+03]\n",
      " [  1.00000000e+00   7.70000000e+02]\n",
      " ..., \n",
      " [  1.00000000e+00   1.02000000e+03]\n",
      " [  1.00000000e+00   1.60000000e+03]\n",
      " [  1.00000000e+00   1.02000000e+03]]\n",
      "[ 1.  1.  1. ...,  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Test feature derivative\n",
    "(example_features, example_output) = get_numpy_data(sales, ['sqft_living'], 'price') \n",
    "my_weights = np.array([0., 0.]) # this makes all the predictions 0\n",
    "test_predictions = predict_output(example_features, my_weights) \n",
    "print (\"Test predictions: {}\").format(test_predictions)\n",
    "print (\"Example outputs: {}\").format(example_output)\n",
    "\n",
    "# just like SFrames 2 numpy arrays can be elementwise subtracted with '-': \n",
    "errors = test_predictions - example_output # prediction errors in this case is just the -example_output\n",
    "feature = example_features[:,0] # let's compute the derivative with respect to 'constant', the \":\" indicates \"all rows\"\n",
    "print(errors)\n",
    "print(\"Example features: {}\").format(example_features)\n",
    "print(feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-23345850022.0\n",
      "-23345850022.0\n"
     ]
    }
   ],
   "source": [
    "derivative = feature_derivative(errors, feature)\n",
    "# print (feature)\n",
    "# print (errors)\n",
    "print derivative\n",
    "print -np.sum(example_output)*2 # should be the same as derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import sqrt # recall that the magnitude/length of a vector [g[0], g[1], g[2]] is sqrt(g[0]^2 + g[1]^2 + g[2]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regression_gradient_descent(feature_matrix, output, initial_weights, step_size, tolerance):\n",
    "    converged = False \n",
    "    weights = np.array(initial_weights) # make sure it's a numpy array\n",
    "    while not converged:\n",
    "        # compute the predictions based on feature_matrix and weights using your predict_output() function\n",
    "        predictions = predict_output(feature_matrix, weights)\n",
    "        # compute the errors as predictions - output\n",
    "        errors = predictions - output\n",
    "        gradient_sum_squares = 0 # initialize the gradient sum of squares\n",
    "        # while we haven't reached the tolerance yet, update each feature's weight\n",
    "        for i in range(len(weights)): # loop over each weight\n",
    "            # Recall that feature_matrix[:, i] is the feature column associated with weights[i]\n",
    "            # compute the derivative for weight[i]:\n",
    "            derivative = feature_derivative(errors, feature_matrix[:,1])\n",
    "            # add the squared value of the derivative to the gradient sum of squares (for assessing convergence)\n",
    "            gradient_sum_squares += derivative**2\n",
    "            # subtract the step size times the derivative from the current weight\n",
    "            weights[i] -= (step_size * derivative)\n",
    "        # compute the square-root of the gradient sum of squares to get the gradient matnigude:\n",
    "        gradient_magnitude = sqrt(gradient_sum_squares)\n",
    "        if gradient_magnitude < tolerance:\n",
    "            converged = True\n",
    "    return(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Gradient Descent as Simple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data,test_data = sales.random_split(.8,seed=0)\n",
    "\n",
    "# let's test out the gradient descent\n",
    "simple_features = ['sqft_living']\n",
    "my_output = train_data['price']\n",
    "(simple_feature_matrix, output) = get_numpy_data(train_data, simple_features, my_output)\n",
    "initial_weights = np.array([-47000., 1.])\n",
    "step_size = 7e-12\n",
    "tolerance = 2.5e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: [[  1.00000000e+00   1.18000000e+03]\n",
      " [  1.00000000e+00   2.57000000e+03]\n",
      " [  1.00000000e+00   7.70000000e+02]\n",
      " ..., \n",
      " [  1.00000000e+00   1.53000000e+03]\n",
      " [  1.00000000e+00   1.60000000e+03]\n",
      " [  1.00000000e+00   1.02000000e+03]]\n",
      "Weights: [ -4.70000000e+04   1.00000000e+00] \n",
      "[['7129300520' datetime.datetime(2014, 10, 13, 0, 0, tzinfo=GMT +0.0)\n",
      "  221900.0 ..., 1340.0 5650.0 1]\n",
      " ['6414100192' datetime.datetime(2014, 12, 9, 0, 0, tzinfo=GMT +0.0)\n",
      "  538000.0 ..., 1690.0 7639.0 1]\n",
      " ['5631500400' datetime.datetime(2015, 2, 25, 0, 0, tzinfo=GMT +0.0)\n",
      "  180000.0 ..., 2720.0 8062.0 1]\n",
      " ..., \n",
      " ['0263000018' datetime.datetime(2014, 5, 21, 0, 0, tzinfo=GMT +0.0)\n",
      "  360000.0 ..., 1530.0 1509.0 1]\n",
      " ['0291310100' datetime.datetime(2015, 1, 16, 0, 0, tzinfo=GMT +0.0)\n",
      "  400000.0 ..., 1410.0 1287.0 1]\n",
      " ['1523300157' datetime.datetime(2014, 10, 15, 0, 0, tzinfo=GMT +0.0)\n",
      "  325000.0 ..., 1020.0 1357.0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature: {}\").format(simple_feature_matrix)\n",
    "print(\"Weights: {} \").format(initial_weights)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Run gradient descent as simple regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data,test_data = sales.random_split(.8,seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's test out the gradient descent\n",
    "simple_features = ['sqft_living']\n",
    "my_output = 'price'\n",
    "(simple_feature_matrix, output) = get_numpy_data(train_data, simple_features, my_output)\n",
    "initial_weights = np.array([-47000., 1.])\n",
    "step_size = 7e-12\n",
    "tolerance = 2.5e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_weight = regression_gradient_descent(simple_feature_matrix, train_data[my_output], initial_weights, step_size, tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-46719.2006469    281.7993531]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz Question: What is the value of the weight for sqft_living -- the second element of ‘simple_weights’ (rounded to 1 decimal place)?\n",
    "Use your newly estimated weights and your predict_output() function to compute the predictions on all the TEST data (you will need to create a numpy array of the test feature_matrix and test output first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.00000000e+00   1.43000000e+03]\n",
      " [  1.00000000e+00   2.95000000e+03]\n",
      " [  1.00000000e+00   1.71000000e+03]\n",
      " ..., \n",
      " [  1.00000000e+00   2.52000000e+03]\n",
      " [  1.00000000e+00   2.31000000e+03]\n",
      " [  1.00000000e+00   1.02000000e+03]]\n",
      "[ 310000.  650000.  233000. ...,  610685.  400000.  402101.]\n"
     ]
    }
   ],
   "source": [
    "(test_simple_feature_matrix, test_output) = get_numpy_data(test_data, simple_features, my_output)\n",
    "print(test_simple_feature_matrix)\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute your predictions using test_simple_feature_matrix and your weights from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 356253.87428756  784588.89100111  435157.69315585 ...,  663415.16916767\n",
      "  604237.30501646  240716.13951614]\n"
     ]
    }
   ],
   "source": [
    "test_predictions = predict_output(test_simple_feature_matrix, test_weight)\n",
    "print (test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz Question: What is the predicted price for the 1st house in the TEST data set for model 1 (round to nearest dollar)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356253.87\n"
     ]
    }
   ],
   "source": [
    "print(\"%0.2f\" % test_predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have the predictions on test data, compute the RSS on the test data set. Save this value for comparison later. Recall that RSS is the sum of the squared errors (difference between prediction and output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.75393142455e+14\n"
     ]
    }
   ],
   "source": [
    "rss = ((test_output - test_predictions)**2).sum()\n",
    "print(rss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_features = ['sqft_living', 'sqft_living15'] # sqft_living15 is the average squarefeet for the nearest 15 neighbors. \n",
    "my_output = 'price'\n",
    "(feature_matrix, output) = get_numpy_data(train_data, model_features, my_output)\n",
    "initial_weights = np.array([-100000., 1., 1.])\n",
    "step_size = 4e-12\n",
    "tolerance = 1e9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the above parameters to estimate the model weights. Record these values for your quiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-99840.65143618    160.34856382    160.34856382]\n"
     ]
    }
   ],
   "source": [
    "mult_test_weight = regression_gradient_descent(feature_matrix, output, initial_weights, step_size, tolerance)\n",
    "print(mult_test_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your newly estimated weights and the predict_output function to compute the predictions on the TEST data. Don't forget to create a numpy array for these features from the test set first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 414878.23841973  716333.53839764  339514.41342525 ...,  708316.11020674\n",
      "  564002.4027705   227270.41875262]\n"
     ]
    }
   ],
   "source": [
    "(mult_test_feature_matrix, test_output) = get_numpy_data(test_data, model_features, my_output)\n",
    "\n",
    "mult_test_predictions = predict_output(mult_test_feature_matrix, mult_test_weight)\n",
    "print(mult_test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz Question: What is the predicted price for the 1st house in the TEST data set for model 2 (round to nearest dollar)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414878.24\n"
     ]
    }
   ],
   "source": [
    "print(\"%0.2f\" % mult_test_predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "What is the actual price for the 1st house in the test data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310000.0\n"
     ]
    }
   ],
   "source": [
    "print(test_data['price'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz Question: Which estimate was closer to the true price for the 1st house on the Test data set, model 1 or model 2?\n",
    "\n",
    "Now use your predictions and the output to compute the RSS for model 2 on TEST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 414878.23841973  716333.53839764  339514.41342525 ...,  708316.11020674\n",
      "  564002.4027705   227270.41875262]\n",
      "[ 310000.  650000.  233000. ...,  610685.  400000.  402101.]\n",
      "RSS: 277538511068266.750000\n"
     ]
    }
   ],
   "source": [
    "print(mult_test_predictions)\n",
    "print(test_output)\n",
    "diff = mult_test_predictions - test_output\n",
    "mult_rss = (diff**2).sum()\n",
    "print(\"RSS: %f\" % mult_rss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz Question: Which model (1 or 2) has lowest RSS on all of the TEST data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.77538511068e+14\n",
      "2.75393142455e+14\n"
     ]
    }
   ],
   "source": [
    "print(mult_rss)\n",
    "print(rss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
